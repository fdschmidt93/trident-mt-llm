defaults:
  - evaluation: text_classification

dataset:
  _target_: datasets.load.load_dataset

preprocessing:
  method:
    map:
      _convert_: all
      batched: true
      batch_size: 125
      fn_kwargs:
        tokenizer: 
          _target_: transformers.AutoTokenizer.from_pretrained
          pretrained_model_name_or_path: ${oc.select:module.model.nllb.pretrained_model_name_or_path,${run.base_model}}
        tokenize_kwargs:
          max_length: ${run.max_length}
        columns:
          # test
          context: flores_passage
          question: question
          label: correct_answer_num
          choices: 
            - mc_answer1
            - mc_answer2
            - mc_answer3
            - mc_answer4
      function:
        _target_: src.mt_llm.processing.preprocess_multiple_choice
        _partial_: true

dataloader:
  _target_: torch.utils.data.dataloader.DataLoader
  collate_fn:
    _target_: src.mt_llm.processing.DataCollatorForMC
    tokenizer: 
      _target_: transformers.AutoTokenizer.from_pretrained
      pretrained_model_name_or_path: ${oc.select:module.model.nllb.pretrained_model_name_or_path,${run.base_model}}
    tokenize_kwargs:
      padding: True
      return_tensors: pt
  # collate_fn:
  #   _target_: src.mt_llm.processing.DataCollatorForMultipleChoice
  #   tokenizer:
  #     _target_: transformers.AutoTokenizer.from_pretrained
  #     pretrained_model_name_or_path: ${oc.select:module.model.nllb.pretrained_model_name_or_path,${run.base_model}}
  #   tokenize_kwargs:
  #     truncation: True
  #     return_tensors: pt
  #     padding: "max_length"
  #     max_length: ${oc.select:run.max_length,512}
  #   columns:
  #     # test
  #     context: flores_passage
  #     question: question
  #     label: correct_answer_num
  #     choices: 
  #       - mc_answer1
  #       - mc_answer2
  #       - mc_answer3
  #       - mc_answer4
      # train/val
      # context: passage
      # question: question
      # label: correct_answer_num
      # choices: 
      #   - answer1
      #   - answer2
      #   - answer3
      #   - answer4
  batch_size: ${run.val_test_batch_size} # copied into all train, val, test
  pin_memory: true # copied into all train, val, test
  shuffle: false # will be copied in to val and test
  num_workers: 0

evaluation:
  metrics:
    acc:
      metric:
        num_classes: 4
    macro_f1:
      metric:
        _partial_: true
        _target_: torchmetrics.functional.f1_score
        task: "multiclass"
        average: "macro"
        num_classes: 4
      # either "eval_step" or "epoch_end"
      compute_on: "epoch_end"
      kwargs: 
        # kwargs for the metric function
        preds: "outputs.preds"
        target: "outputs.labels"
